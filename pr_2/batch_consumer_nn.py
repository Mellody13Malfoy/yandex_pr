#!/usr/bin/env python3
import json
import logging
import time
import os
import sys
from confluent_kafka import Consumer, KafkaError

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –Ω–µ—Ç
os.makedirs('/app/logs', exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'/app/logs/batch_consumer_instance{os.getenv("APP_INSTANCE", "1")}.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(f'BatchConsumer-{os.getenv("APP_INSTANCE", "1")}')

class BatchMessageConsumer:
    def __init__(self, bootstrap_servers, topic, group_id, batch_size=10):
        self.bootstrap_servers = bootstrap_servers
        self.topic = topic
        self.batch_size = batch_size

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–æ–Ω—Å—å—é–º–µ—Ä–∞ (—Ä—É—á–Ω–æ–π –∫–æ–º–º–∏—Ç) - –ü–†–ê–í–ò–õ–¨–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´
        self.config = {
            'bootstrap.servers': bootstrap_servers,
            'group.id': f'{group_id}-instance-{os.getenv("APP_INSTANCE", "1")}',
            'auto.offset.reset': 'earliest',
            'enable.auto.commit': False,  # –†–£–ß–ù–û–ô –∫–æ–º–º–∏—Ç
            'fetch.wait.max.ms': 5000,    # –ñ–¥–µ–º –¥–æ 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –Ω–∞–±–æ—Ä–∞ –±–∞—Ç—á–∞
            'fetch.message.max.bytes': 1048576,  # 1 MB max message size
            'max.partition.fetch.bytes': 1048576,  # 1 MB per partition
            'session.timeout.ms': 30000,
            'heartbeat.interval.ms': 10000
        }

        self.consumer = Consumer(self.config)
        logger.info(f"BatchMessageConsumer initialized")
        logger.info(f"Topic: {topic}")
        logger.info(f"Group ID: {self.config['group.id']}")
        logger.info(f"Instance: {os.getenv('APP_INSTANCE', '1')}")
        logger.info(f"Batch size: {batch_size}")
        logger.info(f"Manual commit: ENABLED")
        logger.info(f"Processing: Loop through batch, commit once")

    def process_batch(self, messages):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ü–∏–∫–ª–µ"""
        logger.info(f"Processing batch of {len(messages)} messages")

        success_count = 0
        error_count = 0

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ü–∏–∫–ª–µ
        for i, msg in enumerate(messages, 1):
            try:
                data = json.loads(msg.value().decode('utf-8'))

                # –ë—ã—Å—Ç—Ä–∞—è —Å–∏–º—É–ª—è—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                time.sleep(0.05)

                logger.debug(f"   [{i}/{len(messages)}] Processing: {data.get('id', 'unknown')}")

                # –°–ª—É—á–∞–π–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∞
                if data.get('message_number', 0) % 20 == 0:
                    raise Exception(f"Batch error for message {data.get('message_number')}")

                success_count += 1

            except Exception as e:
                error_count += 1
                logger.error(f"   Error in message {data.get('id', 'unknown')}: {str(e)}")

        logger.info(f"Batch result: {success_count} success, {error_count} errors")
        return success_count, error_count

    def consume(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è (–ø–∞—á–∫–∞–º–∏ –ø–æ 10)"""
        self.consumer.subscribe([self.topic])
        logger.info("Batch consumer started...")
        logger.info("Strategy: Collect min 10 messages, process in loop, commit once")

        batch_count = 0
        total_messages = 0

        try:
            while True:
                # –°–æ–±–∏—Ä–∞–µ–º –±–∞—Ç—á –∏–∑ –º–∏–Ω–∏–º—É–º 10 —Å–æ–æ–±—â–µ–Ω–∏–π
                batch = []
                start_time = time.time()

                while len(batch) < self.batch_size:
                    msg = self.consumer.poll(1.0)

                    if msg is None:
                        # –ï—Å–ª–∏ –Ω–∞–±—Ä–∞–ª–∏ —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ –∏ –ø—Ä–æ—à–ª–æ –≤—Ä–µ–º—è
                        if len(batch) > 0 and (time.time() - start_time) > 5:
                            logger.info(f"Timeout reached, processing {len(batch)} messages")
                            break
                        continue

                    if msg.error():
                        if msg.error().code() == KafkaError._PARTITION_EOF:
                            continue
                        logger.error(f"Consumer error: {msg.error()}")
                        continue

                    batch.append(msg)

                if not batch:
                    continue

                batch_count += 1
                logger.info(f"üî® Batch #{batch_count}: collected {len(batch)} messages")

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞
                success, errors = self.process_batch(batch)
                total_messages += success

                try:
                    self.consumer.commit(asynchronous=False)
                    logger.info(f"Committed offsets for batch #{batch_count}")
                except Exception as e:
                    logger.error(f"Commit failed: {e}")

                logger.info(f"--- Batch #{batch_count} completed ---")

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–∞–∂–¥—ã–µ 5 –±–∞—Ç—á–µ–π
                if batch_count % 5 == 0:
                    logger.info(f"Statistics: {batch_count} batches, {total_messages} messages total")

        except KeyboardInterrupt:
            logger.info("Consumer stopped by user")
        except Exception as e:
            logger.error(f"Fatal error: {e}", exc_info=True)
        finally:
            self.consumer.close()
            logger.info(f"Total batches processed: {batch_count}")
            logger.info(f"Total messages processed: {total_messages}")

def main():
    bootstrap_servers = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'kafka1:9092,kafka2:9092')
    topic = os.getenv('KAFKA_TOPIC', 'my-replicated-topic')

    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –ª–æ–≥–æ–≤
    os.makedirs('/app/logs', exist_ok=True)

    # –ó–∞–ø—É—Å–∫ –∫–æ–Ω—Å—å—é–º–µ—Ä–∞
    consumer = BatchMessageConsumer(
        bootstrap_servers=bootstrap_servers,
        topic=topic,
        group_id='batch-message-group',
        batch_size=10
    )
    consumer.consume()

if __name__ == '__main__':
    main()
